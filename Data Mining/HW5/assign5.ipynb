{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I SVM implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./OnlineNewsPopularity.csv')\n",
    "df = df.drop(df.columns[list(range(0,2))+list(range(4,7))+list(range(13,39))],axis = 1)\n",
    "dataset = np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_attribute_and_label(data):\n",
    "    x = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    return x,y\n",
    "def convert_label(threshold,label):\n",
    "    new_label = copy.deepcopy(label)\n",
    "    for i,val in enumerate(label):\n",
    "        if (val >= threshold):\n",
    "            new_label[i] = 1\n",
    "        else:\n",
    "            new_label[i] = -1\n",
    "    return new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the dataset\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(dataset)\n",
    "train = dataset[:1000]\n",
    "dev = dataset[1000:2000]\n",
    "test = dataset[2001:3001]\n",
    "f'the train size is {train.shape[0]}, the dev shape is {dev.shape[0]}, and the test shape is {test.shape[0]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x ,train_y = split_attribute_and_label(train)\n",
    "dev_x ,dev_y = split_attribute_and_label(dev)\n",
    "test_x ,test_y = split_attribute_and_label(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdScaler = StandardScaler()\n",
    "stdScaler.fit(train_x)\n",
    "centered_train = stdScaler.transform(train_x)\n",
    "centered_dev = stdScaler.transform(dev_x)\n",
    "centered_test = stdScaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_train_y = convert_label(2000,train_y)\n",
    "conv_dev_y = convert_label(2000,dev_y)\n",
    "conv_test_y = convert_label(2000,test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kernel(dataset,kernel,spread = None,dataset1 = None):\n",
    "    if dataset1 == None:\n",
    "        dataset1 = np.copy(dataset)\n",
    "    empty_kernel = np.zeros((dataset.shape[0],dataset.shape[0]))\n",
    "    for i in range(dataset.shape[0]):\n",
    "        for j in range(i,dataset.shape[0]):\n",
    "            X = dataset[i,:]\n",
    "            Y = dataset1[j,:]\n",
    "            if kernel == 'linear':\n",
    "                K_ij = compute_linear_kernel(X,Y)\n",
    "            if kernel == 'gaussian':\n",
    "                K_ij = compute_gaussian_kernel(X,Y,spread)\n",
    "            empty_kernel[i][j] = K_ij\n",
    "            empty_kernel[j][i] = K_ij\n",
    "    return  empty_kernel\n",
    "\n",
    "def compute_linear_kernel(X,Y):\n",
    "    return np.dot(X.T,Y)     \n",
    "def _compute_linear_kernel(X,Y):\n",
    "    return np.dot(X,Y.T)     \n",
    "def compute_gaussian_kernel(X,Y,spread):\n",
    "\treturn np.exp(-1 * (np.linalg.norm(X - Y)**2 / (2 * spread)) )\n",
    "def _gaussian_kernel(data_matrix_1, data_matrix_2, spread):\n",
    "    kernel_matrix = np.zeros((len(data_matrix_1), len(data_matrix_2)))\n",
    "    for i in range(len(data_matrix_1)):\n",
    "        for j in range(len(data_matrix_2)):\n",
    "            numer = np.linalg.norm(data_matrix_1[i] - data_matrix_2[j]) ** 2\n",
    "            denom = float(2 * (spread))\n",
    "            kernel_matrix[i][j] = math.exp(-numer/denom)\n",
    "    return kernel_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(x, y, kernel, loss, eps, C, spread=None):\n",
    "    if loss == 'hinge':\n",
    "        if kernel == 'linear':\n",
    "            K = generate_kernel(x,kernel)\n",
    "        elif kernel == 'gaussian':\n",
    "            K = generate_kernel(x,kernel,spread)\n",
    "    K = K+1\n",
    "    eta = np.asarray([1/k for k in np.diag(K)])\n",
    "    alpha = np.random.rand(K.shape[0])\n",
    "    index = [i for i in range(K.shape[0])]\n",
    "    l1_norm = np.Inf\n",
    "    while l1_norm > eps:\n",
    "        alpha_prev = np.copy(alpha)\n",
    "        np.random.shuffle(index)\n",
    "        for k_index in index:\n",
    "            alpha[k_index] = alpha[k_index] + eta[k_index] *\\\n",
    "                (1 - y[k_index] * (np.sum(np.multiply(np.multiply(alpha, y), K.T[k_index]))))\n",
    "            if alpha[k_index] < 0:\n",
    "                alpha[k_index] = 0\n",
    "            if loss == \"hinge\" and alpha[k_index] > C:\n",
    "                alpha[k_index] = C\n",
    "        l1_norm = np.linalg.norm((alpha - alpha_prev))\n",
    "    return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(alpha, y, kernel):\n",
    "    x = np.sign(np.sum((alpha * y * kernel),1))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the best C for linear alpha, we perform a grid search from C = 0.001 to 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.linspace(0.001,0.01,15):\n",
    "    linear_alpha = SVM(centered_train,conv_train_y,'linear','hinge',0.001,i)\n",
    "    linear_pred = prediction(linear_alpha,conv_train_y,_compute_linear_kernel(centered_dev,centered_train)+1)\n",
    "    #make sure the model is learning\n",
    "    assert(np.sum(linear_pred == -1) != 1000)\n",
    "    assert(np.sum(linear_pred == 1) != 1000)\n",
    "    print(f'The precision is {np.sum(conv_dev_y == linear_pred)/1000} on dev set when C is {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best precison on dev set for linear alpha occurs when C is 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the best C for gaussian alpha, we perform a grid search from C = 1 to 10 and spread from 10 to 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.linspace(1,10,3):\n",
    "    for j in np.linspace(50,200,3):\n",
    "        gaussian_alpha = SVM(centered_train,conv_train_y,'gaussian','hinge',0.001,i,j)\n",
    "        gaussian_pred = prediction(gaussian_alpha,conv_train_y,_gaussian_kernel(centered_dev,centered_train,j)+1)\n",
    "        #make sure the model is learning, we do not use an assert here because the search space is large\n",
    "        if np.sum(gaussian_pred == -1) == 1000 or np.sum(gaussian_pred == 1) == 1000:\n",
    "            print(f'model is not learning when C is {i} and Spread is {j}')\n",
    "        else:\n",
    "            print(f'The precision is {np.sum(conv_dev_y == gaussian_pred)/1000} on dev set when C is {i} and Spread is {j}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best combination for gaussian kernel occurs when C is 10 and spread is 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_alpha = SVM(centered_train,conv_train_y,'linear','hinge',0.001,0.005)\n",
    "linear_pred = prediction(linear_alpha,conv_train_y,_compute_linear_kernel(centered_test,centered_train)+1)\n",
    "print(f'The accuarcy of linear SVM on test set is{np.sum(conv_test_y == linear_pred)/1000} when C is {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_alpha = SVM(centered_train,conv_train_y,'gaussian','hinge',0.001,5.5,50)\n",
    "gaussian_pred = prediction(gaussian_alpha,conv_train_y,_gaussian_kernel(centered_test,centered_train,125)+1)\n",
    "print(f'The accuarcy of gaussian SVM on test set is {np.sum(conv_test_y == gaussian_pred)/1000}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II Exam 1 Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset = open('seeds_dataset.txt', 'r')\n",
    "dataset_list = []\n",
    "for line in dataset:\n",
    "    data = line.strip().split('\\t')\n",
    "    while '' in data:\n",
    "        data.remove('')\n",
    "    assert(len(data) == 8)\n",
    "    dataset_list.append([float(data[i]) for i in range(7)])\n",
    "dataset = pd.DataFrame(data = np.array(dataset_list), columns=range(7)).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean(X):\n",
    "    return X.sum(axis=0) / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = np.zeros((210,28))\n",
    "for points in range(dataset.shape[0]):\n",
    "    counter = 0\n",
    "    for i in range(dataset.shape[1]):\n",
    "        for j in range(i,dataset.shape[1]):\n",
    "            if i != j:\n",
    "                transformed_data[points][counter] = math.sqrt(2)*dataset[points,i]*dataset[points,j]\n",
    "            else:\n",
    "                transformed_data[points][counter] = dataset[points,i]*dataset[points,j]\n",
    "            counter += 1\n",
    "transformed_data = transformed_data - get_mean(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper functions\n",
    "def length(a):\n",
    "    return np.sqrt(np.dot(a.T,a))\n",
    "def normalize(a):\n",
    "    return a/length(a)\n",
    "def get_cov(X,X_mean):\n",
    "    return (np.dot((X-X_mean).T,(X-X_mean))/X.shape[0])\n",
    "def get_mean(X):\n",
    "    return X.sum(axis=0) / X.shape[0]\n",
    "def total_variance(X,X_mean):\n",
    "    return np.sum((X-X_mean)**2) / X.shape[0]\n",
    "def project_data(eigen_vectors,centered_kernel):\n",
    "    basis = np.column_stack([eigen_vectors[:, 1-i]\n",
    "                           for i in range(2)])    \n",
    "    projection = np.dot(basis.T,centered_kernel)\n",
    "    return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "A = np.copy(transformed_data)\n",
    "A = A - get_mean(A)\n",
    "## find out what is d\n",
    "d = A.shape[1]\n",
    "epsilon = 10e-6\n",
    "intermediate_result = list()\n",
    "X_i = np.random.random_sample([d,2])\n",
    "X_i[:,0] = normalize(X_i[:,0])\n",
    "X_i[:,1] = normalize(X_i[:,1])\n",
    "cov = get_cov(A,get_mean(A))\n",
    "while len(intermediate_result)<2 or np.linalg.norm(intermediate_result[-1] - intermediate_result[-2])>=epsilon:\n",
    "    X_iplus1 = np.dot(cov,X_i)\n",
    "    X_iplus1[:,1] = X_iplus1[:,1] - np.dot((np.dot(X_iplus1[:,1].T,X_iplus1[:,0])/np.dot(X_iplus1[:,0].T,X_iplus1[:,0])),X_iplus1[:,0])\n",
    "    X_iplus1[:,0] = normalize(X_iplus1[:,0])\n",
    "    X_iplus1[:,1] = normalize(X_iplus1[:,1])\n",
    "    X_i = X_iplus1\n",
    "    intermediate_result.append(X_iplus1)\n",
    "u_1 = X_iplus1[:,0]\n",
    "u_2 = X_iplus1[:,1]\n",
    "labda_1 = np.dot(np.dot(u_1.T,cov.T),u_1)/(np.dot(u_1.T,u_1))\n",
    "labda_2 = np.dot(np.dot(u_2.T,cov.T),u_2)/(np.dot(u_2.T,u_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The best direction is:')\n",
    "u_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1583098d49b8b63b24ba78fec75676b625853923384d7c0eb5f87db36da8a08e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
