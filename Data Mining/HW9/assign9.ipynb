{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import logsumexp\n",
    "import random\n",
    "import math\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Micha\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3553: DtypeWarning: Columns (5,6) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "train = np.array(pd.read_csv('./codon_usage.csv'))\n",
    "# shuffle the dataset\n",
    "train = np.delete(train, (486,5063), axis=0)\n",
    "y = np.copy(train[:,0])\n",
    "X = np.delete(train,(0,1,2,3,4), axis=1)\n",
    "X = X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: Only 20% of the data are used (stratified so it does not matter) as discussed in Thread #307"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "sss.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_Kernel(x_t,x_i,h):\n",
    "    return (1/((2*math.pi)**(64/2)))*np.exp(-np.sum((x_i-x_t)*(x_i-x_t),axis = 1, keepdims=True)/(2*h**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findAttractor(x,D,h,eps):\n",
    "    x_prev = np.copy(x)\n",
    "    x_next = np.copy(x_prev)\n",
    "    t = 0\n",
    "    while t == 0 or np.linalg.norm(x_next-x_prev)>=eps:\n",
    "        x_prev = np.copy(x_next)\n",
    "        k_i = Gaussian_Kernel(x_next,D,h)\n",
    "        numerator = np.sum((k_i*D),axis = 0)\n",
    "        denominator= np.sum(k_i)\n",
    "        x_next = numerator/denominator\n",
    "        t+=1\n",
    "    return x_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_hat(x_star,n,h,d,D):\n",
    "    partial = np.sum(Gaussian_Kernel(x_star,D,h))*1/(n*h**d)\n",
    "    return partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.2\n",
    "eta = 5e16\n",
    "eps = 0.001\n",
    "alpha = list()\n",
    "R = dict()\n",
    "f_hats = list()\n",
    "used_index = []\n",
    "selected_index = next(sss.split(X,y))[1]\n",
    "selected_train = (X[next(sss.split(X,y))[1]])\n",
    "for i,x in enumerate(selected_train):\n",
    "    x_star = findAttractor(x,selected_train,h,eps)\n",
    "    density = f_hat(x_star,selected_train.shape[0],h,64,X)\n",
    "    f_hats.append(density)\n",
    "    if  density>= eta:\n",
    "        alpha.append(x_star)\n",
    "        R[len(alpha)-1] = i\n",
    "        used_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 4e-3\n",
    "adj_table = [[] for i in range(len(alpha))]\n",
    "for i in range(len(alpha)):\n",
    "    for j in range(i+1,len(alpha)):\n",
    "        if (np.linalg.norm(alpha[i]-alpha[j])) <= eps:\n",
    "            adj_table[i].append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS(temp, v, visited,adj_table):\n",
    "    visited[v] = True\n",
    "    temp.append(v)\n",
    "    for i in adj_table[v]:\n",
    "        if visited[i] == False:\n",
    "            temp = DFS(temp, i, visited,adj_table)\n",
    "    return temp\n",
    " \n",
    "def connectedComponents(alpha,adj_table):\n",
    "    visited = [False]*len(alpha)\n",
    "    cc = []\n",
    "    for v in range(len(alpha)):\n",
    "        if visited[v] == False:\n",
    "            temp = []\n",
    "            cc.append(DFS(temp, v, visited,adj_table))\n",
    "    return cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = connectedComponents(alpha,adj_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [-1]*len(selected_index)\n",
    "for i in range(len(cc)):\n",
    "    for j in cc[i]:\n",
    "        pred[R[j]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(data):\n",
    "    num_count = set()\n",
    "    for i in data:\n",
    "        num_count.add(i)\n",
    "    num_count = list(num_count)\n",
    "    data = np.copy(data)\n",
    "    zeros = np.zeros((data.shape[0],len(num_count)))\n",
    "    for i in range(data.shape[0]):\n",
    "        zeros[i,num_count.index(data[i])] = 1\n",
    "    return zeros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_temp = one_hot_encoding(y[next(sss.split(X,y))[1]])\n",
    "label = np.argmax(y_temp,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = label[used_index]\n",
    "pred = np.array(pred)[used_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Micha\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Converting `np.integer` or `np.signedinteger` to a dtype is deprecated. The current result is `np.dtype(np.int_)` which is not strictly correct. Note that the result depends on the system. To ensure stable results use may want to use `np.int64` or `np.int32`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "contigency_table = np.zeros((11,len(cc)),dtype = np.integer)\n",
    "for i in range(len(pred)):\n",
    "    contigency_table[label[i]][pred[i]] += 1\n",
    "col_sum = np.sum(contigency_table,axis = 0)\n",
    "row_sum = np.sum(contigency_table,axis = 1)\n",
    "H_T = -np.sum(col_sum/np.sum(col_sum)*np.log(col_sum/np.sum(col_sum)))\n",
    "H_C = -np.sum(row_sum/np.sum(row_sum)*np.log(row_sum/np.sum(row_sum)))\n",
    "I_CT = 0\n",
    "for i in range(11):\n",
    "    for j in range(len(cc)):\n",
    "        if (contigency_table[i][j] != 0):\n",
    "            I_CT += (contigency_table[i][j]/np.sum(row_sum))*np.log((contigency_table[i][j]*np.sum(row_sum))/((row_sum[i])*(col_sum[j])))\n",
    "NMI = I_CT/(np.sqrt(H_C*H_T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Only 20% of the data are used (stratified using scipy so it does not matter) as discussed in Thread #307 due to efficiency problem\n",
      "Class Size is: 9\n",
      "The class distribution is: [1910, 3, 39, 427, 15, 14, 74, 21, 3]\n",
      "The NMI Score is: 0.3362311094353266\n"
     ]
    }
   ],
   "source": [
    "print(\"Note: Only 20% of the data are used (stratified using scipy so it does not matter) as discussed in Thread #307 due to efficiency problem\")\n",
    "print(f\"Class Size is: {len(cc)}\")\n",
    "print(f\"The class distribution is: {[len(cc[i]) for i in range(len(cc))]}\")\n",
    "print(f\"The NMI Score is: {NMI}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1583098d49b8b63b24ba78fec75676b625853923384d7c0eb5f87db36da8a08e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
